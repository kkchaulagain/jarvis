{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfeb20dc-1919-47f8-8d39-5dbaec49af91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: happytransformer in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: tqdm>=4.43 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from happytransformer) (4.64.0)\n",
      "Requirement already satisfied: datasets>=1.6.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from happytransformer) (2.2.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from happytransformer) (3.20.1)\n",
      "Requirement already satisfied: torch>=1.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from happytransformer) (1.11.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from happytransformer) (0.1.96)\n",
      "Requirement already satisfied: transformers>=4.4.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from happytransformer) (4.19.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (3.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (1.22.4)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (8.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (2.27.1)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (0.18.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (3.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (0.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (21.3)\n",
      "Requirement already satisfied: dill<0.3.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (0.3.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (2022.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (0.70.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.0->happytransformer) (4.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.43->happytransformer) (0.4.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.4.0->happytransformer) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.4.0->happytransformer) (0.12.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.4.0->happytransformer) (3.7.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.4.0->happytransformer) (2022.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->datasets>=1.6.0->happytransformer) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets>=1.6.0->happytransformer) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets>=1.6.0->happytransformer) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets>=1.6.0->happytransformer) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets>=1.6.0->happytransformer) (3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (1.7.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (6.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets>=1.6.0->happytransformer) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets>=1.6.0->happytransformer) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets>=1.6.0->happytransformer) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install happytransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61a13373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "caea8138-222d-458a-8a43-c4204bf4ddb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6bdc78a-c550-4e07-8a16-4432248984be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from happytransformer import HappyGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f1e6fa7-dc20-4748-89be-ca1007017944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
      "Model config GPTNeoConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-125M\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      6\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
      "Model config GPTNeoConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-125M\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      6\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/pytorch_model.bin from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\b0ace3b93ace62067a246888f1e54e2d3ec20807d4d3e27ac602eef3b7091c0b.6525df88f1d5a2d33d95ce2458ef6af9658fe7d1393d6707e0e318779ccc68ff\n",
      "All model checkpoint weights were used when initializing GPTNeoForCausalLM.\n",
      "\n",
      "All the weights of GPTNeoForCausalLM were initialized from the model checkpoint at EleutherAI/gpt-neo-125M.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPTNeoForCausalLM for predictions without further training.\n",
      "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
      "Model config GPTNeoConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-125M\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      6\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/vocab.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\08c00c4159e921d4c941ac75732643373aba509d9b352a82bbbb043a94058d98.a552555fdda56a1c7c9a285bccfd44ac8e4b9e26c8c9b307831b3ea3ac782b45\n",
      "loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/merges.txt from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\12305762709d884a770efe7b0c68a7f4bc918da44e956058d43da0d12f7bea20.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/special_tokens_map.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\6c3239a63aaf46ec7625b38abfe41fc2ce0b25f90800aefe6526256340d4ab6d.2b8bf81243d08385c806171bc7ced6d2a0dcc7f896ca637f4e777418f7f0cc3c\n",
      "loading file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/tokenizer_config.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\3cc88b3aa29bb2546db2dc21783292e2a086bb7158c7b5ceddeb24158a85c183.e74f7c3643ee79eb023ead36008be72fe726dada60fa3b2a0569925cfefa1e74\n",
      "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
      "Model config GPTNeoConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-125M\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      6\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
      "Model config GPTNeoConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-125M\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      6\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation',model='EleutherAI/gpt-neo-125M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "963ee3db-97a6-4cfa-9770-fb5ac729a746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
      "Model config GPTNeoConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-125M\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      6\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/pytorch_model.bin from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\b0ace3b93ace62067a246888f1e54e2d3ec20807d4d3e27ac602eef3b7091c0b.6525df88f1d5a2d33d95ce2458ef6af9658fe7d1393d6707e0e318779ccc68ff\n",
      "All model checkpoint weights were used when initializing GPTNeoForCausalLM.\n",
      "\n",
      "All the weights of GPTNeoForCausalLM were initialized from the model checkpoint at EleutherAI/gpt-neo-125M.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPTNeoForCausalLM for predictions without further training.\n",
      "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-125M/resolve/main/config.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\29380fef22a43cbfb3d3a6c8e2f4fd951459584d87c34e4621b30580a54aca84.f0f7ebddfc6e15a23ac33e7fa95cd8cca05edf87cc74f9e3be7905f538a59762\n",
      "Model config GPTNeoConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-125M\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      6\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "  7%|â–‹         | 7/100 [08:51<1:57:35, 75.87s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Acer\\Documents\\work\\ai\\jarvis\\gptneo.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Acer/Documents/work/ai/jarvis/gptneo.ipynb#ch0000004?line=0'>1</a>\u001b[0m happy_gen \u001b[39m=\u001b[39m HappyGeneration(\u001b[39m\"\u001b[39;49m\u001b[39mGPT-NEO\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mEleutherAI/gpt-neo-125M\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\happytransformer\\happy_generation.py:57\u001b[0m, in \u001b[0;36mHappyGeneration.__init__\u001b[1;34m(self, model_type, model_name, load_path, use_auth_token)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_generation.py?line=53'>54</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_generation.py?line=54'>55</a>\u001b[0m     model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39mfrom_pretrained(model_name, use_auth_token\u001b[39m=\u001b[39muse_auth_token)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_generation.py?line=56'>57</a>\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(model_type, model_name, model, use_auth_token\u001b[39m=\u001b[39;49muse_auth_token, load_path\u001b[39m=\u001b[39;49mload_path)\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_generation.py?line=57'>58</a>\u001b[0m device_number \u001b[39m=\u001b[39m detect_cuda_device_number()\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_generation.py?line=59'>60</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline \u001b[39m=\u001b[39m TextGenerationPipeline(model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, tokenizer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer, device\u001b[39m=\u001b[39mdevice_number)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\happytransformer\\happy_transformer.py:25\u001b[0m, in \u001b[0;36mHappyTransformer.__init__\u001b[1;34m(self, model_type, model_name, model, load_path, use_auth_token)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_transformer.py?line=22'>23</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(load_path)\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_transformer.py?line=23'>24</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_transformer.py?line=24'>25</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(model_name, use_auth_token\u001b[39m=\u001b[39;49muse_auth_token)\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_transformer.py?line=25'>26</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_transformer.py?line=26'>27</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:573\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/auto/tokenization_auto.py?line=570'>571</a>\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[39m=\u001b[39m TOKENIZER_MAPPING[\u001b[39mtype\u001b[39m(config)]\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/auto/tokenization_auto.py?line=571'>572</a>\u001b[0m \u001b[39mif\u001b[39;00m tokenizer_class_fast \u001b[39mand\u001b[39;00m (use_fast \u001b[39mor\u001b[39;00m tokenizer_class_py \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/auto/tokenization_auto.py?line=572'>573</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer_class_fast\u001b[39m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/auto/tokenization_auto.py?line=573'>574</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/auto/tokenization_auto.py?line=574'>575</a>\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer_class_py \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1723\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/tokenization_utils_base.py?line=1720'>1721</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/tokenization_utils_base.py?line=1721'>1722</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/tokenization_utils_base.py?line=1722'>1723</a>\u001b[0m         resolved_vocab_files[file_id] \u001b[39m=\u001b[39m cached_path(\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/tokenization_utils_base.py?line=1723'>1724</a>\u001b[0m             file_path,\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/tokenization_utils_base.py?line=1724'>1725</a>\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/tokenization_utils_base.py?line=1725'>1726</a>\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/tokenization_utils_base.py?line=1726'>1727</a>\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/tokenization_utils_base.py?line=1727'>1728</a>\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/tokenization_utils_base.py?line=1728'>1729</a>\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/tokenization_utils_base.py?line=1729'>1730</a>\u001b[0m             use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/tokenization_utils_base.py?line=1730'>1731</a>\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/tokenization_utils_base.py?line=1731'>1732</a>\u001b[0m         )\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/tokenization_utils_base.py?line=1733'>1734</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/tokenization_utils_base.py?line=1734'>1735</a>\u001b[0m         \u001b[39mif\u001b[39;00m local_files_only:\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\hub.py:282\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=277'>278</a>\u001b[0m     local_files_only \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=279'>280</a>\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=280'>281</a>\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=281'>282</a>\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=282'>283</a>\u001b[0m         url_or_filename,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=283'>284</a>\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=284'>285</a>\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=285'>286</a>\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=286'>287</a>\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=287'>288</a>\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=288'>289</a>\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=289'>290</a>\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=290'>291</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=291'>292</a>\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=292'>293</a>\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=293'>294</a>\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\hub.py:485\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=482'>483</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m local_files_only:\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=483'>484</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=484'>485</a>\u001b[0m         r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mhead(url, headers\u001b[39m=\u001b[39;49mheaders, allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, proxies\u001b[39m=\u001b[39;49mproxies, timeout\u001b[39m=\u001b[39;49metag_timeout)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=485'>486</a>\u001b[0m         _raise_for_status(r)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/utils/hub.py?line=486'>487</a>\u001b[0m         etag \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mX-Linked-Etag\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mETag\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\api.py:102\u001b[0m, in \u001b[0;36mhead\u001b[1;34m(url, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/api.py?line=90'>91</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a HEAD request.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/api.py?line=91'>92</a>\u001b[0m \n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/api.py?line=92'>93</a>\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/api.py?line=97'>98</a>\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/api.py?line=98'>99</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/api.py?line=100'>101</a>\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/api.py?line=101'>102</a>\u001b[0m \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39m\u001b[39mhead\u001b[39m\u001b[39m'\u001b[39m, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/api.py?line=56'>57</a>\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/api.py?line=57'>58</a>\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/api.py?line=58'>59</a>\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/api.py?line=59'>60</a>\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/api.py?line=60'>61</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/sessions.py?line=523'>524</a>\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/sessions.py?line=524'>525</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/sessions.py?line=525'>526</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/sessions.py?line=526'>527</a>\u001b[0m }\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/sessions.py?line=527'>528</a>\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/sessions.py?line=528'>529</a>\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/sessions.py?line=530'>531</a>\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/sessions.py?line=641'>642</a>\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/sessions.py?line=643'>644</a>\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/sessions.py?line=644'>645</a>\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/sessions.py?line=646'>647</a>\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/sessions.py?line=647'>648</a>\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=437'>438</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=438'>439</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=439'>440</a>\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=440'>441</a>\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=441'>442</a>\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=442'>443</a>\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=443'>444</a>\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=444'>445</a>\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=445'>446</a>\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=446'>447</a>\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=447'>448</a>\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=448'>449</a>\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=449'>450</a>\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=450'>451</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=452'>453</a>\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=453'>454</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/requests/adapters.py?line=454'>455</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m'\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=699'>700</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=701'>702</a>\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=702'>703</a>\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=703'>704</a>\u001b[0m     conn,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=704'>705</a>\u001b[0m     method,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=705'>706</a>\u001b[0m     url,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=706'>707</a>\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=707'>708</a>\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=708'>709</a>\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=709'>710</a>\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=710'>711</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=712'>713</a>\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=713'>714</a>\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=714'>715</a>\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=715'>716</a>\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=716'>717</a>\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=383'>384</a>\u001b[0m \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=384'>385</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=385'>386</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=386'>387</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=387'>388</a>\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=388'>389</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:1040\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=1037'>1038</a>\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=1038'>1039</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=1039'>1040</a>\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=1041'>1042</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=1042'>1043</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=1043'>1044</a>\u001b[0m         (\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=1044'>1045</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=1049'>1050</a>\u001b[0m         InsecureRequestWarning,\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connectionpool.py?line=1050'>1051</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connection.py:414\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=404'>405</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=405'>406</a>\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_certs\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=406'>407</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mca_cert_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=409'>410</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(context, \u001b[39m\"\u001b[39m\u001b[39mload_default_certs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=410'>411</a>\u001b[0m ):\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=411'>412</a>\u001b[0m     context\u001b[39m.\u001b[39mload_default_certs()\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=413'>414</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=414'>415</a>\u001b[0m     sock\u001b[39m=\u001b[39;49mconn,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=415'>416</a>\u001b[0m     keyfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_file,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=416'>417</a>\u001b[0m     certfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_file,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=417'>418</a>\u001b[0m     key_password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_password,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=418'>419</a>\u001b[0m     ca_certs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_certs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=419'>420</a>\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_dir,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=420'>421</a>\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_data,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=421'>422</a>\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=422'>423</a>\u001b[0m     ssl_context\u001b[39m=\u001b[39;49mcontext,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=423'>424</a>\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=424'>425</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=426'>427</a>\u001b[0m \u001b[39m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=427'>428</a>\u001b[0m \u001b[39m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=428'>429</a>\u001b[0m \u001b[39m# for the host.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=429'>430</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=430'>431</a>\u001b[0m     default_ssl_context\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=431'>432</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_version \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=432'>433</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock, \u001b[39m\"\u001b[39m\u001b[39mversion\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=433'>434</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock\u001b[39m.\u001b[39mversion() \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mTLSv1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTLSv1.1\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/connection.py?line=434'>435</a>\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=436'>437</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=437'>438</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn HTTPS request has been made, but the SNI (Server Name \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=438'>439</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIndication) extension to TLS is not available on this platform. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=444'>445</a>\u001b[0m         SNIMissingWarning,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=445'>446</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=447'>448</a>\u001b[0m \u001b[39mif\u001b[39;00m send_sni:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=448'>449</a>\u001b[0m     ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=449'>450</a>\u001b[0m         sock, context, tls_in_tls, server_hostname\u001b[39m=\u001b[39;49mserver_hostname\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=450'>451</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=451'>452</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=452'>453</a>\u001b[0m     ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=489'>490</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=491'>492</a>\u001b[0m \u001b[39mif\u001b[39;00m server_hostname:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=492'>493</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39;49mwrap_socket(sock, server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=493'>494</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/urllib3/util/ssl_.py?line=494'>495</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39mwrap_socket(sock)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:512\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=505'>506</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=506'>507</a>\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=507'>508</a>\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=508'>509</a>\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=509'>510</a>\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=510'>511</a>\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=511'>512</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=512'>513</a>\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=513'>514</a>\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=514'>515</a>\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=515'>516</a>\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=516'>517</a>\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=517'>518</a>\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=518'>519</a>\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=519'>520</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1070\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1066'>1067</a>\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1067'>1068</a>\u001b[0m             \u001b[39m# non-blocking\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1068'>1069</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1069'>1070</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1070'>1071</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1071'>1072</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1341\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1338'>1339</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mand\u001b[39;00m block:\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1339'>1340</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1340'>1341</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1341'>1342</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/ssl.py?line=1342'>1343</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "happy_gen = HappyGeneration(\"GPT-NEO\",\"EleutherAI/gpt-neo-125M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142269f-7098-4a48-89ad-4eee1bef67a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_gen.save(\"model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24a5d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"Google was founded in 1998 by Larry Page and Sergey Brin while\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65791178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "text = generator(prompt_text , do_sample=True, max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6cde2395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google was founded in 1998 by Larry Page and Sergey Brin while still a young son. At the time he was working for a company that had launched some of the biggest software companies in the worldâ€”a company that made him famous by the sheer intensity of their efforts.\n",
      "\n",
      "And what was Google?\n",
      "\n",
      "â€œGoogle is always looking at startups,â€ he said. He spoke after work.\n",
      "\n",
      "The CEO had been working for someone from Google, though, which also happened to be one of his co-founders. It was Larry Page who brought Sergey to the startup.\n",
      "\n",
      "Now Google, whose name means â€œGoogle,â€ is working on a new search platform. The company would be â€œgoing on a real fast journeyâ€ but would never get as big as Google.\n",
      "\n",
      "â€œGoogle is doing something that is something different than what weâ€™ve been doing a year and a quarter after we launched Google,â€ he said.\n"
     ]
    }
   ],
   "source": [
    "print(text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8716c374-06b2-48ca-9628-74b00a97a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from happytransformer import GENSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3943fa75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c40d9c-226b-44cc-add5-a3b99e1a5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from happytransformer import GENTrainArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5def102-e5ce-4537-ba0b-c4f58adb5fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = GENTrainArgs( num_train_epochs =100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de5babdf-83b6-4c27-9670-0c9350c41e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2022 19:47:01 - INFO - happytransformer.happy_transformer -   Preprocessing dataset...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<?, ?it/s]\n",
      "06/05/2022 19:47:01 - INFO - happytransformer.happy_transformer -   Training...\n",
      "PyTorch: setting up devices\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 100\n",
      "  7%|â–‹         | 7/100 [03:44<45:35, 29.42s/it]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Acer\\Documents\\work\\ai\\jarvis\\gptneo.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Acer/Documents/work/ai/jarvis/gptneo.ipynb#ch0000009?line=0'>1</a>\u001b[0m happy_gen\u001b[39m.\u001b[39;49mtrain(\u001b[39m\"\u001b[39;49m\u001b[39mdata.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m,args\u001b[39m=\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\happytransformer\\happy_generation.py:134\u001b[0m, in \u001b[0;36mHappyGeneration.train\u001b[1;34m(self, input_filepath, args)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_generation.py?line=130'>131</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_generation.py?line=131'>132</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid args type. Use a GENTrainArgs object or a dictionary\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_generation.py?line=133'>134</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_trainer\u001b[39m.\u001b[39;49mtrain(input_filepath\u001b[39m=\u001b[39;49minput_filepath, dataclass_args\u001b[39m=\u001b[39;49mmethod_dataclass_args)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\happytransformer\\gen\\trainer.py:77\u001b[0m, in \u001b[0;36mGENTrainer.train\u001b[1;34m(self, input_filepath, dataclass_args)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/gen/trainer.py?line=72'>73</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_json(dataclass_args\u001b[39m.\u001b[39msave_preprocessed_data_path, tokenized_dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/gen/trainer.py?line=74'>75</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mTraining...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/gen/trainer.py?line=76'>77</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train(tokenized_dataset[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m], dataclass_args, default_data_collator)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\happytransformer\\happy_trainer.py:101\u001b[0m, in \u001b[0;36mHappyTrainer._run_train\u001b[1;34m(self, dataset, dataclass_args, data_collator)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_trainer.py?line=92'>93</a>\u001b[0m training_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_training_args(dataclass_args, tmp_dir_name)\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_trainer.py?line=93'>94</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_trainer.py?line=94'>95</a>\u001b[0m     model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel,\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_trainer.py?line=95'>96</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_trainer.py?line=98'>99</a>\u001b[0m     data_collator\u001b[39m=\u001b[39mdata_collator,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_trainer.py?line=99'>100</a>\u001b[0m )\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/happytransformer/happy_trainer.py?line=100'>101</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:1317\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1311'>1312</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1313'>1314</a>\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1314'>1315</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1315'>1316</a>\u001b[0m )\n\u001b[1;32m-> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1316'>1317</a>\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1317'>1318</a>\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1318'>1319</a>\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1319'>1320</a>\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1320'>1321</a>\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1321'>1322</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:1554\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1551'>1552</a>\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1552'>1553</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1553'>1554</a>\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1555'>1556</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1556'>1557</a>\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1557'>1558</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1558'>1559</a>\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1559'>1560</a>\u001b[0m ):\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1560'>1561</a>\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=1561'>1562</a>\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:2183\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=2179'>2180</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=2181'>2182</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautocast_smart_context_manager():\n\u001b[1;32m-> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=2182'>2183</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=2184'>2185</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=2185'>2186</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\trainer.py:2215\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=2212'>2213</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=2213'>2214</a>\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=2214'>2215</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=2215'>2216</a>\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=2216'>2217</a>\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/trainer.py?line=2217'>2218</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:739\u001b[0m, in \u001b[0;36mGPTNeoForCausalLM.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=730'>731</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=731'>732</a>\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=732'>733</a>\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=733'>734</a>\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=734'>735</a>\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=735'>736</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=736'>737</a>\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=738'>739</a>\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=739'>740</a>\u001b[0m     input_ids,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=740'>741</a>\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=741'>742</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=742'>743</a>\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=743'>744</a>\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=744'>745</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=745'>746</a>\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=746'>747</a>\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=747'>748</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=748'>749</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=749'>750</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=750'>751</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=751'>752</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=753'>754</a>\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:618\u001b[0m, in \u001b[0;36mGPTNeoModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=609'>610</a>\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=610'>611</a>\u001b[0m         create_custom_forward(block),\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=611'>612</a>\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=614'>615</a>\u001b[0m         head_mask[i],\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=615'>616</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=616'>617</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=617'>618</a>\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=618'>619</a>\u001b[0m         hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=619'>620</a>\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=620'>621</a>\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=621'>622</a>\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=622'>623</a>\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=623'>624</a>\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=624'>625</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=626'>627</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=627'>628</a>\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:323\u001b[0m, in \u001b[0;36mGPTNeoBlock.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=320'>321</a>\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=321'>322</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_1(hidden_states)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=322'>323</a>\u001b[0m attn_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=323'>324</a>\u001b[0m     hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=324'>325</a>\u001b[0m     layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=325'>326</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=326'>327</a>\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=327'>328</a>\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=328'>329</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=329'>330</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=330'>331</a>\u001b[0m attn_output \u001b[39m=\u001b[39m attn_outputs[\u001b[39m0\u001b[39m]  \u001b[39m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=331'>332</a>\u001b[0m outputs \u001b[39m=\u001b[39m attn_outputs[\u001b[39m1\u001b[39m:]\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:275\u001b[0m, in \u001b[0;36mGPTNeoAttention.forward\u001b[1;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=265'>266</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=266'>267</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=267'>268</a>\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=272'>273</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=273'>274</a>\u001b[0m ):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=274'>275</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=275'>276</a>\u001b[0m         hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=276'>277</a>\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=277'>278</a>\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=278'>279</a>\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=279'>280</a>\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=280'>281</a>\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=281'>282</a>\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:238\u001b[0m, in \u001b[0;36mGPTNeoSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, layer_past, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=234'>235</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=235'>236</a>\u001b[0m     present \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=237'>238</a>\u001b[0m attn_output, attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_attn(query, key, value, attention_mask, head_mask)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=239'>240</a>\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_heads(attn_output, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=240'>241</a>\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_proj(attn_output)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\gpt_neo\\modeling_gpt_neo.py:197\u001b[0m, in \u001b[0;36mGPTNeoSelfAttention._attn\u001b[1;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=192'>193</a>\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=193'>194</a>\u001b[0m     \u001b[39m# Apply the attention mask\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=194'>195</a>\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights \u001b[39m+\u001b[39m attention_mask\n\u001b[1;32m--> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=196'>197</a>\u001b[0m attn_weights \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49msoftmax(attn_weights, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=197'>198</a>\u001b[0m attn_weights \u001b[39m=\u001b[39m attn_weights\u001b[39m.\u001b[39mto(value\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py?line=198'>199</a>\u001b[0m attn_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn_dropout(attn_weights)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:1818\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/functional.py?line=1815'>1816</a>\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/functional.py?line=1816'>1817</a>\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/functional.py?line=1817'>1818</a>\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/functional.py?line=1818'>1819</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Acer/AppData/Local/Programs/Python/Python310/lib/site-packages/torch/nn/functional.py?line=1819'>1820</a>\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "happy_gen.train(\"data.txt\",args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2f4f422-b16f-4b02-8e60-f7223a507096",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_sampling_settings = GENSettings(no_repeat_ngram_size=2,temperature=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24501161-12c6-4374-87b3-2e2ed8f499a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "result = happy_gen.generate_text(\"start deployment process\",args=top_k_sampling_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4c3c460-b531-40b5-bbac-767c9f00fb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "### Deployment process\n",
      "Deployment processes are a set of steps that are used to deploy a new deployment to a target system. The deployment processes can be a single process, a group of processes, or a combination of these. A\n"
     ]
    }
   ],
   "source": [
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ebb45-3dad-47c1-8e1a-1218c1d3ffd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8798b4-a386-4f72-a17f-4cd5d856864f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58837b1b657ea91009af8409fc244ae3b5ccf93ea980d6fb6b80adc5f697f4cc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
