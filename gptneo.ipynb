{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfeb20dc-1919-47f8-8d39-5dbaec49af91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: happytransformer in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: transformers>=4.4.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from happytransformer) (4.19.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from happytransformer) (0.1.96)\n",
      "Requirement already satisfied: datasets>=1.6.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from happytransformer) (2.2.2)\n",
      "Requirement already satisfied: torch>=1.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from happytransformer) (1.11.0)\n",
      "Requirement already satisfied: tqdm>=4.43 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from happytransformer) (4.64.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from happytransformer) (3.20.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (2022.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (1.22.4)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (0.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (0.7.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (1.4.2)\n",
      "Requirement already satisfied: dill<0.3.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (0.3.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (2.27.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (3.8.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (8.0.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (3.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (21.3)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets>=1.6.0->happytransformer) (0.70.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.0->happytransformer) (4.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.43->happytransformer) (0.4.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.4.0->happytransformer) (2022.6.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.4.0->happytransformer) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.4.0->happytransformer) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers>=4.4.0->happytransformer) (3.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->datasets>=1.6.0->happytransformer) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets>=1.6.0->happytransformer) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets>=1.6.0->happytransformer) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets>=1.6.0->happytransformer) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets>=1.6.0->happytransformer) (2022.5.18.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets>=1.6.0->happytransformer) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets>=1.6.0->happytransformer) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets>=1.6.0->happytransformer) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets>=1.6.0->happytransformer) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install happytransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6bdc78a-c550-4e07-8a16-4432248984be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from happytransformer import HappyGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "963ee3db-97a6-4cfa-9770-fb5ac729a746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/config.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\42252c2220ae3f9f1ea86a994b63e1dcab20953ba8982117c2384587f7c01c5d.102e6e06599c480a8e55be9ba8dc6226140c958f3cd489f61627520db6817595\n",
      "Model config GPTNeoConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-1.3B\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      12\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50,\n",
      "      \"temperature\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/pytorch_model.bin from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\7c5fac9d60b015cbc7c007ab8fe6d0512787fbaef81968922959898c49468d73.4c6a483fbfb5a25ac384bfcd71a1ff15245f06583a00c4ab4c44ed0f761f0b08\n",
      "All model checkpoint weights were used when initializing GPTNeoForCausalLM.\n",
      "\n",
      "All the weights of GPTNeoForCausalLM were initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPTNeoForCausalLM for predictions without further training.\n",
      "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/config.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\42252c2220ae3f9f1ea86a994b63e1dcab20953ba8982117c2384587f7c01c5d.102e6e06599c480a8e55be9ba8dc6226140c958f3cd489f61627520db6817595\n",
      "Model config GPTNeoConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-1.3B\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      12\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50,\n",
      "      \"temperature\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/vocab.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\6111bc9bbed617156dc5c0b9fa9d6793147619aad08053f03b3697f1a5027973.a1b97b074a5ac71fad0544c8abc1b3581803d73832476184bde6cff06a67b6bb\n",
      "loading file https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/merges.txt from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\ec80888cdc98108f625f7ec7a29ec449eb361ae1325aa1e7e63006ce962c071c.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/special_tokens_map.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\1ae5a53fe395100a9213705940d92cc94554a2269777c062d951d1b710c39bb8.3ae9ae72462581d20e36bc528e9c47bb30cd671bb21add40ca0b24a0be9fac22\n",
      "loading file https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/tokenizer_config.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\5fe35a59019a6fb05bfa29a31b59d407cd81ae59da93e6953772a783b740b4c0.c31b6b7d3225be0c43bc0f8e5d84d03a8b49fdb6b9f6009bbfff1f9cc5ec18bc\n",
      "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/config.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\42252c2220ae3f9f1ea86a994b63e1dcab20953ba8982117c2384587f7c01c5d.102e6e06599c480a8e55be9ba8dc6226140c958f3cd489f61627520db6817595\n",
      "Model config GPTNeoConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-1.3B\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      12\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50,\n",
      "      \"temperature\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/config.json from cache at C:\\Users\\Acer/.cache\\huggingface\\transformers\\42252c2220ae3f9f1ea86a994b63e1dcab20953ba8982117c2384587f7c01c5d.102e6e06599c480a8e55be9ba8dc6226140c958f3cd489f61627520db6817595\n",
      "Model config GPTNeoConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-neo-1.3B\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTNeoForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0,\n",
      "  \"attention_layers\": [\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\",\n",
      "    \"global\",\n",
      "    \"local\"\n",
      "  ],\n",
      "  \"attention_types\": [\n",
      "    [\n",
      "      [\n",
      "        \"global\",\n",
      "        \"local\"\n",
      "      ],\n",
      "      12\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embed_dropout\": 0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": null,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"gpt_neo\",\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"resid_dropout\": 0,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50,\n",
      "      \"temperature\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257,\n",
      "  \"window_size\": 256\n",
      "}\n",
      "\n",
      "06/06/2022 08:39:41 - INFO - happytransformer.happy_transformer -   Using model: cpu\n"
     ]
    }
   ],
   "source": [
    "happy_gen = HappyGeneration(\"GPT-NEO\",\"EleutherAI/gpt-neo-1.3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/06/2022 07:28:06 - INFO - happytransformer.happy_transformer -   Using model: cpu\n"
     ]
    }
   ],
   "source": [
    "# use gpu if available\n",
    "\n",
    "happy_gen= HappyGeneration(\"GPT-NEO\",\"EleutherAI/gpt-neo-125M\", load_path=\"model/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5142269f-7098-4a48-89ad-4eee1bef67a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in model/config.json\n",
      "Model weights saved in model/pytorch_model.bin\n",
      "tokenizer config file saved in model/tokenizer_config.json\n",
      "Special tokens file saved in model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "happy_gen.save(\"model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8716c374-06b2-48ca-9628-74b00a97a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from happytransformer import GENSettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29c40d9c-226b-44cc-add5-a3b99e1a5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from happytransformer import GENTrainArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5def102-e5ce-4537-ba0b-c4f58adb5fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = GENTrainArgs( num_train_epochs =1, learning_rate=0.0001, batch_size=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de5babdf-83b6-4c27-9670-0c9350c41e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/06/2022 09:49:04 - INFO - happytransformer.happy_transformer -   Preprocessing dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/default to C:\\Users\\Acer\\.cache\\huggingface\\datasets\\text\\default-68223d133a01b672\\0.0.0\\4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 100.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to C:\\Users\\Acer\\.cache\\huggingface\\datasets\\text\\default-68223d133a01b672\\0.0.0\\4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 55.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.62ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.84ba/s]\n",
      "06/06/2022 09:49:06 - INFO - happytransformer.happy_transformer -   Training...\n",
      "PyTorch: setting up devices\n",
      "c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "100%|██████████| 1/1 [03:15<00:00, 195.28s/it]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [03:15<00:00, 195.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 195.4285, 'train_samples_per_second': 0.005, 'train_steps_per_second': 0.005, 'train_loss': 0.3113323152065277, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "happy_gen.train(\"data.txt\",args=args)\n",
    "# save the model after 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e497f0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in model/config.json\n",
      "Model weights saved in model/pytorch_model.bin\n",
      "tokenizer config file saved in model/tokenizer_config.json\n",
      "Special tokens file saved in model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "happy_gen.save(\"model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2f4f422-b16f-4b02-8e60-f7223a507096",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GENSettings.__init__() got an unexpected keyword argument 'end_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Acer\\Documents\\work\\ai\\jarvis\\gptneo.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Acer/Documents/work/ai/jarvis/gptneo.ipynb#ch0000010?line=0'>1</a>\u001b[0m top_k_sampling_settings \u001b[39m=\u001b[39m GENSettings(no_repeat_ngram_size\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,temperature\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m, top_k\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,end_token\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m###\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: GENSettings.__init__() got an unexpected keyword argument 'end_token'"
     ]
    }
   ],
   "source": [
    "top_k_sampling_settings = GENSettings(no_repeat_ngram_size=2,temperature=0.9, top_k=10,do_sample=True,end_token=\"###\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24501161-12c6-4374-87b3-2e2ed8f499a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "result = happy_gen.generate_text('{\"prompt\": \"change to bookmundi\"',args=top_k_sampling_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4c3c460-b531-40b5-bbac-767c9f00fb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "}}{\"change_to_bookmundin\": {\"promp\": change_prom_changetobook_mund_in}}{{\"book\": book_books}}{{{\"mund\": mund_machines}}}}\n",
      "{\"{change\":\n"
     ]
    }
   ],
   "source": [
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ebb45-3dad-47c1-8e1a-1218c1d3ffd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8798b4-a386-4f72-a17f-4cd5d856864f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58837b1b657ea91009af8409fc244ae3b5ccf93ea980d6fb6b80adc5f697f4cc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
